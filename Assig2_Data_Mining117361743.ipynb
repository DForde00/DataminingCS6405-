{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assig2-Data Mining117361743.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CS3033/CS6405 - Data Mining - Second Assignment\n",
        "\n",
        "### Submission\n",
        "\n",
        "This assignment is **due on 06/04/22 at 23:59**. You should submit a single .ipnyb file with your python code and analysis electronically via Canvas.\n",
        "Please note that this assignment will account for 25 Marks of your module grade.\n",
        "\n",
        "### Declaration\n",
        "\n",
        "By submitting this assignment. I agree to the following:\n",
        "\n",
        "<font color=\"red\">“I have read and understand the UCC academic policy on plagiarism, and agree to the requirements set out thereby in relation to plagiarism and referencing. I confirm that I have referenced and acknowledged properly all sources used in the preparation of this assignment.\n",
        "I declare that this assignment is entirely my own work based on my personal study. I further declare that I have not engaged the services of another to either assist me in, or complete this assignment”</font>\n",
        "\n",
        "### Objective\n",
        "\n",
        "The Boolean satisfiability (SAT) problem consists in determining whether a Boolean formula F is satisfiable or not. F is represented by a pair (X, C), where X is a set of Boolean variables and C is a set of clauses in Conjunctive Normal Form (CNF). Each clause is a disjunction of literals (a variable or its negation). This problem is one of the most widely studied combinatorial problems in computer science. It is the classic NP-complete problem. Over the past number of decades, a significant amount of research work has focused on solving SAT problems with both complete and incomplete solvers.\n",
        "\n",
        "Recent advances in supervised learning have provided powerful techniques for classifying problems. In this project, we see the SAT problem as a classification problem. Given a Boolean formula (represented by a vector of features), we are asked to predict if it is satisfiable or not.\n",
        "\n",
        "In this project, we represent SAT problems with a vector of 327 features with general information about the problem, e.g., number of variables, number of clauses, fraction of horn clauses in the problem, etc. There is no need to understand the features to be able to complete the assignment.\n",
        "\n",
        "The dataset is available at:\n",
        "https://github.com/andvise/DataAnalyticsDatasets/blob/main/dm_assignment2/sat_dataset_train.csv\n",
        "\n",
        "This is original unpublished data."
      ],
      "metadata": {
        "id": "8WfrCFmLHxYu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "Oav9G1WSJ1nH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://github.com/andvise/DataAnalyticsDatasets/blob/6d5738101d173b97c565f143f945dedb9c42a400/dm_assignment2/sat_dataset_train.csv?raw=true\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "DE0kM0QsJ1En",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "7ab268bc-decd-4cbe-a0ba-bd8717b3a3a8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     c   v  clauses_vars_ratio  vars_clauses_ratio  vcg_var_mean  \\\n",
              "0  420  10           42.000000            0.023810      0.600000   \n",
              "1  230  20           11.500000            0.086957      0.137826   \n",
              "2  240  16           15.000000            0.066667      0.300000   \n",
              "3  424  30           14.133333            0.070755      0.226415   \n",
              "4  162  19            8.526316            0.117284      0.139701   \n",
              "\n",
              "   vcg_var_coeff  vcg_var_min  vcg_var_max  vcg_var_entropy  vcg_clause_mean  \\\n",
              "0       0.000000     0.600000     0.600000         0.000000         0.600000   \n",
              "1       0.089281     0.117391     0.160870         2.180946         0.137826   \n",
              "2       0.000000     0.300000     0.300000         0.000000         0.300000   \n",
              "3       0.485913     0.056604     0.452830         2.220088         0.226415   \n",
              "4       0.121821     0.111111     0.185185         1.940843         0.139701   \n",
              "\n",
              "   ...  rwh_0_max    rwh_1_mean  rwh_1_coeff     rwh_1_min     rwh_1_max  \\\n",
              "0  ...    78750.0      0.000008          0.0  7.875000e-06      0.000008   \n",
              "1  ...  6646875.0  17433.722184          1.0  2.981244e-12  34867.444369   \n",
              "2  ...   500000.0   1525.878932          0.0  1.525879e+03   1525.878932   \n",
              "3  ...    87500.0      0.000122          1.0  6.535723e-14      0.000245   \n",
              "4  ...  5859400.0  16591.494310          1.0  6.912726e-42  33182.988621   \n",
              "\n",
              "     rwh_2_mean  rwh_2_coeff     rwh_2_min     rwh_2_max  target  \n",
              "0  2.385082e-21          0.0  2.385082e-21  2.385082e-21       1  \n",
              "1  1.727721e+04          1.0  1.358551e-53  3.455442e+04       0  \n",
              "2  1.525879e+03          0.0  1.525879e+03  1.525879e+03       1  \n",
              "3  8.218628e-07          1.0  1.499676e-61  1.643726e-06       0  \n",
              "4  1.665903e+04          1.0  0.000000e+00  3.331807e+04       1  \n",
              "\n",
              "[5 rows x 328 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58f11f93-21a0-451c-9259-a7c4cbf2fa52\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c</th>\n",
              "      <th>v</th>\n",
              "      <th>clauses_vars_ratio</th>\n",
              "      <th>vars_clauses_ratio</th>\n",
              "      <th>vcg_var_mean</th>\n",
              "      <th>vcg_var_coeff</th>\n",
              "      <th>vcg_var_min</th>\n",
              "      <th>vcg_var_max</th>\n",
              "      <th>vcg_var_entropy</th>\n",
              "      <th>vcg_clause_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>rwh_0_max</th>\n",
              "      <th>rwh_1_mean</th>\n",
              "      <th>rwh_1_coeff</th>\n",
              "      <th>rwh_1_min</th>\n",
              "      <th>rwh_1_max</th>\n",
              "      <th>rwh_2_mean</th>\n",
              "      <th>rwh_2_coeff</th>\n",
              "      <th>rwh_2_min</th>\n",
              "      <th>rwh_2_max</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>420</td>\n",
              "      <td>10</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>0.023810</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>...</td>\n",
              "      <td>78750.0</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.875000e-06</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>2.385082e-21</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.385082e-21</td>\n",
              "      <td>2.385082e-21</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>230</td>\n",
              "      <td>20</td>\n",
              "      <td>11.500000</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.137826</td>\n",
              "      <td>0.089281</td>\n",
              "      <td>0.117391</td>\n",
              "      <td>0.160870</td>\n",
              "      <td>2.180946</td>\n",
              "      <td>0.137826</td>\n",
              "      <td>...</td>\n",
              "      <td>6646875.0</td>\n",
              "      <td>17433.722184</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.981244e-12</td>\n",
              "      <td>34867.444369</td>\n",
              "      <td>1.727721e+04</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.358551e-53</td>\n",
              "      <td>3.455442e+04</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>240</td>\n",
              "      <td>16</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>...</td>\n",
              "      <td>500000.0</td>\n",
              "      <td>1525.878932</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.525879e+03</td>\n",
              "      <td>1525.878932</td>\n",
              "      <td>1.525879e+03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.525879e+03</td>\n",
              "      <td>1.525879e+03</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>424</td>\n",
              "      <td>30</td>\n",
              "      <td>14.133333</td>\n",
              "      <td>0.070755</td>\n",
              "      <td>0.226415</td>\n",
              "      <td>0.485913</td>\n",
              "      <td>0.056604</td>\n",
              "      <td>0.452830</td>\n",
              "      <td>2.220088</td>\n",
              "      <td>0.226415</td>\n",
              "      <td>...</td>\n",
              "      <td>87500.0</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.535723e-14</td>\n",
              "      <td>0.000245</td>\n",
              "      <td>8.218628e-07</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.499676e-61</td>\n",
              "      <td>1.643726e-06</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>162</td>\n",
              "      <td>19</td>\n",
              "      <td>8.526316</td>\n",
              "      <td>0.117284</td>\n",
              "      <td>0.139701</td>\n",
              "      <td>0.121821</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.185185</td>\n",
              "      <td>1.940843</td>\n",
              "      <td>0.139701</td>\n",
              "      <td>...</td>\n",
              "      <td>5859400.0</td>\n",
              "      <td>16591.494310</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.912726e-42</td>\n",
              "      <td>33182.988621</td>\n",
              "      <td>1.665903e+04</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.331807e+04</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 328 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58f11f93-21a0-451c-9259-a7c4cbf2fa52')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-58f11f93-21a0-451c-9259-a7c4cbf2fa52 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-58f11f93-21a0-451c-9259-a7c4cbf2fa52');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "WOqpQTS-K8EN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccffdf1a-063f-4a05-af27-da96bcd8b0e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "c                       int64\n",
              "v                       int64\n",
              "clauses_vars_ratio    float64\n",
              "vars_clauses_ratio    float64\n",
              "vcg_var_mean          float64\n",
              "                       ...   \n",
              "rwh_2_mean            float64\n",
              "rwh_2_coeff           float64\n",
              "rwh_2_min             float64\n",
              "rwh_2_max             float64\n",
              "target                  int64\n",
              "Length: 328, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'].value_counts()"
      ],
      "metadata": {
        "id": "N8MCvTYTKw4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2404573-a98c-4557-e54b-9da24124ef93"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    976\n",
              "0    953\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "import numpy as np\n",
        "import sklearn \n",
        "from sklearn import preprocessing\n",
        "from sklearn import neighbors\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# replace any infinite vals with NaN and then replace all NaN with 0\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df = df.fillna(0)\n",
        "\n",
        "# target labels\n",
        "y = df[\"target\"].values\n",
        "\n",
        "# dataframe of ONLY the features\n",
        "X = df.drop(columns = [\"target\"])\n",
        "\n",
        "# split normalised features into 70% train and 30% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
        "\n",
        "# Use a min max scaler to normalise the data\n",
        "sc = preprocessing.MinMaxScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# convert to a dataframe just to make visualisation of the data easier\n",
        "X_train_df = pd.DataFrame(X_train)\n",
        "X_train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "SciCQVnxVREC",
        "outputId": "c09f0622-3693-4789-ec81-98e7e960cbb1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4         5         6    \\\n",
              "0     0.126522  0.062500  0.333333  0.022222  0.289783  0.000000  0.297953   \n",
              "1     0.394389  0.758929  0.088212  0.105112  0.005227  0.051762  0.014553   \n",
              "2     0.048174  0.062500  0.120690  0.076462  0.150827  0.000000  0.160596   \n",
              "3     0.061938  0.035714  0.259770  0.031366  0.214118  0.184379  0.141565   \n",
              "4     0.409741  0.392857  0.186462  0.047238  0.019006  0.014643  0.029428   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1345  0.062467  0.116071  0.086207  0.107505  0.096242  0.056781  0.098211   \n",
              "1346  0.409741  0.392857  0.186462  0.047238  0.019006  0.014643  0.029428   \n",
              "1347  0.131286  0.191964  0.115709  0.079906  0.055398  0.041846  0.061521   \n",
              "1348  0.249338  0.125000  0.350192  0.020651  0.225009  0.388078  0.048072   \n",
              "1349  0.835363  0.254464  0.603741  0.007403  0.036068  0.060149  0.036456   \n",
              "\n",
              "           7         8         9    ...       317       318           319  \\\n",
              "0     0.288924  0.000000  0.289783  ...  0.116364  0.012800  5.989472e-03   \n",
              "1     0.005964  0.336816  0.005227  ...  0.000002  0.080000  4.146299e-04   \n",
              "2     0.149800  0.000000  0.150827  ...  0.025455  0.080000  4.629544e-02   \n",
              "3     0.285481  0.489595  0.214118  ...  0.027084  0.190000  3.567503e-01   \n",
              "4     0.018256  0.165175  0.019006  ...  0.145484  0.042000  1.371386e-04   \n",
              "...        ...       ...       ...  ...       ...       ...           ...   \n",
              "1345  0.103686  0.260600  0.096242  ...  0.109091  0.012080  3.115980e-06   \n",
              "1346  0.018256  0.165175  0.019006  ...  0.145600  0.042000  1.371083e-04   \n",
              "1347  0.057610  0.259160  0.055398  ...  0.145455  0.016016  6.075131e-07   \n",
              "1348  0.535132  0.593980  0.225009  ...  0.003258  0.000512  3.373711e-16   \n",
              "1349  0.041434  0.713439  0.036068  ...  0.003642  0.410000  2.186375e-02   \n",
              "\n",
              "           320            321           322           323       324  \\\n",
              "0     0.000000   1.190291e-02  2.994736e-03  3.945657e-03  0.000000   \n",
              "1     1.000000  6.658070e-157  4.146299e-04  2.731445e-04  1.000000   \n",
              "2     1.000000   1.573274e-11  4.629544e-02  3.156526e-02  1.000000   \n",
              "3     1.000000   3.912742e-08  3.567503e-01  2.280460e-01  1.000000   \n",
              "4     0.999428   1.558468e-07  1.370994e-04  1.247159e-04  0.999210   \n",
              "...        ...            ...           ...           ...       ...   \n",
              "1345  0.008394   6.140424e-06  1.571069e-06  2.052525e-06  0.007983   \n",
              "1346  0.999428   1.557780e-07  1.370691e-04  1.247160e-04  0.999210   \n",
              "1347  0.000381   1.206854e-06  3.038724e-07  3.940541e-07  0.000264   \n",
              "1348  0.634005   2.453850e-16  2.756330e-16  1.464385e-40  1.000000   \n",
              "1349  1.000000   2.472961e-17  2.186375e-02  1.429894e-02  1.000000   \n",
              "\n",
              "               325           326  \n",
              "0     1.247583e-02  1.972829e-03  \n",
              "1     0.000000e+00  2.731445e-04  \n",
              "2     2.665337e-37  3.156526e-02  \n",
              "3     2.888843e-19  2.280460e-01  \n",
              "4     3.113659e-07  1.246667e-04  \n",
              "...            ...           ...  \n",
              "1345  6.438098e-06  1.034455e-06  \n",
              "1346  3.113663e-07  1.246667e-04  \n",
              "1347  1.245636e-06  1.970791e-07  \n",
              "1348  1.442707e-49  1.464385e-40  \n",
              "1349  2.195265e-42  1.429894e-02  \n",
              "\n",
              "[1350 rows x 327 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-527c9138-96e8-435f-a785-a056435614ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>317</th>\n",
              "      <th>318</th>\n",
              "      <th>319</th>\n",
              "      <th>320</th>\n",
              "      <th>321</th>\n",
              "      <th>322</th>\n",
              "      <th>323</th>\n",
              "      <th>324</th>\n",
              "      <th>325</th>\n",
              "      <th>326</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.126522</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.022222</td>\n",
              "      <td>0.289783</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.297953</td>\n",
              "      <td>0.288924</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.289783</td>\n",
              "      <td>...</td>\n",
              "      <td>0.116364</td>\n",
              "      <td>0.012800</td>\n",
              "      <td>5.989472e-03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.190291e-02</td>\n",
              "      <td>2.994736e-03</td>\n",
              "      <td>3.945657e-03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.247583e-02</td>\n",
              "      <td>1.972829e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.394389</td>\n",
              "      <td>0.758929</td>\n",
              "      <td>0.088212</td>\n",
              "      <td>0.105112</td>\n",
              "      <td>0.005227</td>\n",
              "      <td>0.051762</td>\n",
              "      <td>0.014553</td>\n",
              "      <td>0.005964</td>\n",
              "      <td>0.336816</td>\n",
              "      <td>0.005227</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>4.146299e-04</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.658070e-157</td>\n",
              "      <td>4.146299e-04</td>\n",
              "      <td>2.731445e-04</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.731445e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.048174</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.120690</td>\n",
              "      <td>0.076462</td>\n",
              "      <td>0.150827</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.160596</td>\n",
              "      <td>0.149800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.150827</td>\n",
              "      <td>...</td>\n",
              "      <td>0.025455</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>4.629544e-02</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.573274e-11</td>\n",
              "      <td>4.629544e-02</td>\n",
              "      <td>3.156526e-02</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.665337e-37</td>\n",
              "      <td>3.156526e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.061938</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.259770</td>\n",
              "      <td>0.031366</td>\n",
              "      <td>0.214118</td>\n",
              "      <td>0.184379</td>\n",
              "      <td>0.141565</td>\n",
              "      <td>0.285481</td>\n",
              "      <td>0.489595</td>\n",
              "      <td>0.214118</td>\n",
              "      <td>...</td>\n",
              "      <td>0.027084</td>\n",
              "      <td>0.190000</td>\n",
              "      <td>3.567503e-01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.912742e-08</td>\n",
              "      <td>3.567503e-01</td>\n",
              "      <td>2.280460e-01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.888843e-19</td>\n",
              "      <td>2.280460e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.409741</td>\n",
              "      <td>0.392857</td>\n",
              "      <td>0.186462</td>\n",
              "      <td>0.047238</td>\n",
              "      <td>0.019006</td>\n",
              "      <td>0.014643</td>\n",
              "      <td>0.029428</td>\n",
              "      <td>0.018256</td>\n",
              "      <td>0.165175</td>\n",
              "      <td>0.019006</td>\n",
              "      <td>...</td>\n",
              "      <td>0.145484</td>\n",
              "      <td>0.042000</td>\n",
              "      <td>1.371386e-04</td>\n",
              "      <td>0.999428</td>\n",
              "      <td>1.558468e-07</td>\n",
              "      <td>1.370994e-04</td>\n",
              "      <td>1.247159e-04</td>\n",
              "      <td>0.999210</td>\n",
              "      <td>3.113659e-07</td>\n",
              "      <td>1.246667e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1345</th>\n",
              "      <td>0.062467</td>\n",
              "      <td>0.116071</td>\n",
              "      <td>0.086207</td>\n",
              "      <td>0.107505</td>\n",
              "      <td>0.096242</td>\n",
              "      <td>0.056781</td>\n",
              "      <td>0.098211</td>\n",
              "      <td>0.103686</td>\n",
              "      <td>0.260600</td>\n",
              "      <td>0.096242</td>\n",
              "      <td>...</td>\n",
              "      <td>0.109091</td>\n",
              "      <td>0.012080</td>\n",
              "      <td>3.115980e-06</td>\n",
              "      <td>0.008394</td>\n",
              "      <td>6.140424e-06</td>\n",
              "      <td>1.571069e-06</td>\n",
              "      <td>2.052525e-06</td>\n",
              "      <td>0.007983</td>\n",
              "      <td>6.438098e-06</td>\n",
              "      <td>1.034455e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1346</th>\n",
              "      <td>0.409741</td>\n",
              "      <td>0.392857</td>\n",
              "      <td>0.186462</td>\n",
              "      <td>0.047238</td>\n",
              "      <td>0.019006</td>\n",
              "      <td>0.014643</td>\n",
              "      <td>0.029428</td>\n",
              "      <td>0.018256</td>\n",
              "      <td>0.165175</td>\n",
              "      <td>0.019006</td>\n",
              "      <td>...</td>\n",
              "      <td>0.145600</td>\n",
              "      <td>0.042000</td>\n",
              "      <td>1.371083e-04</td>\n",
              "      <td>0.999428</td>\n",
              "      <td>1.557780e-07</td>\n",
              "      <td>1.370691e-04</td>\n",
              "      <td>1.247160e-04</td>\n",
              "      <td>0.999210</td>\n",
              "      <td>3.113663e-07</td>\n",
              "      <td>1.246667e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1347</th>\n",
              "      <td>0.131286</td>\n",
              "      <td>0.191964</td>\n",
              "      <td>0.115709</td>\n",
              "      <td>0.079906</td>\n",
              "      <td>0.055398</td>\n",
              "      <td>0.041846</td>\n",
              "      <td>0.061521</td>\n",
              "      <td>0.057610</td>\n",
              "      <td>0.259160</td>\n",
              "      <td>0.055398</td>\n",
              "      <td>...</td>\n",
              "      <td>0.145455</td>\n",
              "      <td>0.016016</td>\n",
              "      <td>6.075131e-07</td>\n",
              "      <td>0.000381</td>\n",
              "      <td>1.206854e-06</td>\n",
              "      <td>3.038724e-07</td>\n",
              "      <td>3.940541e-07</td>\n",
              "      <td>0.000264</td>\n",
              "      <td>1.245636e-06</td>\n",
              "      <td>1.970791e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1348</th>\n",
              "      <td>0.249338</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.350192</td>\n",
              "      <td>0.020651</td>\n",
              "      <td>0.225009</td>\n",
              "      <td>0.388078</td>\n",
              "      <td>0.048072</td>\n",
              "      <td>0.535132</td>\n",
              "      <td>0.593980</td>\n",
              "      <td>0.225009</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003258</td>\n",
              "      <td>0.000512</td>\n",
              "      <td>3.373711e-16</td>\n",
              "      <td>0.634005</td>\n",
              "      <td>2.453850e-16</td>\n",
              "      <td>2.756330e-16</td>\n",
              "      <td>1.464385e-40</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.442707e-49</td>\n",
              "      <td>1.464385e-40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1349</th>\n",
              "      <td>0.835363</td>\n",
              "      <td>0.254464</td>\n",
              "      <td>0.603741</td>\n",
              "      <td>0.007403</td>\n",
              "      <td>0.036068</td>\n",
              "      <td>0.060149</td>\n",
              "      <td>0.036456</td>\n",
              "      <td>0.041434</td>\n",
              "      <td>0.713439</td>\n",
              "      <td>0.036068</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003642</td>\n",
              "      <td>0.410000</td>\n",
              "      <td>2.186375e-02</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.472961e-17</td>\n",
              "      <td>2.186375e-02</td>\n",
              "      <td>1.429894e-02</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.195265e-42</td>\n",
              "      <td>1.429894e-02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1350 rows × 327 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-527c9138-96e8-435f-a785-a056435614ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-527c9138-96e8-435f-a785-a056435614ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-527c9138-96e8-435f-a785-a056435614ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# non-normalised data\n",
        "X1_train, X2_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n"
      ],
      "metadata": {
        "id": "5FyLRl_pKBQ4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tasks\n",
        "\n",
        "## Basic models and evaluation (5 Marks)\n",
        "\n",
        "Using Scikit-learn, train and evaluate K-NN and decision tree classifiers using 70% of the dataset from training and 30% for testing. For this part of the project, we are not interested in optimising the parameters; we just want to get an idea of the dataset. Compare the results of both classifiers."
      ],
      "metadata": {
        "id": "MTvkBPQvITf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "# a fucntion that makes a Knn, lets user specify num of neibhors, fits and evaluates\n",
        "\n",
        "def knn(X1, y1, X2, y2, k):\n",
        "\n",
        "    knn = neighbors.KNeighborsClassifier(n_neighbors = k)\n",
        "    knn.fit(X1, y1)\n",
        "\n",
        "    return(print(\"Accuracy of knn:\", knn.score(X2, y2)))\n",
        "\n",
        "# a function that makes the decision tree, fits and evaluates\n",
        "def decision_tree(X1, y1, X2, y2):\n",
        "    clf = tree.DecisionTreeClassifier()\n",
        "    clf = clf.fit(X1, y1)\n",
        "    y_pred = clf.predict(X2)\n",
        "    # Model Accuracy, how often is the classifier correct?\n",
        "    return(print(\"Accuracy of Decision Tree:\", sklearn.metrics.accuracy_score(y2, y_pred)))\n"
      ],
      "metadata": {
        "id": "Zl0VXO0YH1nG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn(X_train, y_train, X_test,  y_test, 5)\n",
        "\n",
        "decision_tree(X_train, y_train, X_test,  y_test)"
      ],
      "metadata": {
        "id": "bNR_J9u2kNQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a39f7eb-091f-4e25-dcd6-6e443aa86d72"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of knn: 0.8911917098445595\n",
            "Accuracy of Decision Tree: 0.9775474956822107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both models have a high accuracy with the decision tree performing roughly 10% better than the nearest neighbours model. In general a KNN will perform better than a tree based model if given a large enough dataset however despite the size of the dataset herein it may simply be a case of it does not reach the \"size threshold\" so to speak whereby it allows the KNN to perform better. "
      ],
      "metadata": {
        "id": "0jLDoyhT3P3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Robust evaluation (10 Marks)\n",
        "\n",
        "In this section, we are interested in more rigorous techniques by implementing more sophisticated methods, for instance:\n",
        "* Hold-out and cross-validation.\n",
        "* Hyper-parameter tuning.\n",
        "* Feature reduction.\n",
        "* Feature normalisation.\n",
        "\n",
        "Your report should provide concrete information of your reasoning; everything should be well-explained.\n",
        "\n",
        "Do not get stressed if the things you try do not improve the accuracy. The key to geting good marks is to show that you evaluated different methods and that you correctly selected the configuration."
      ],
      "metadata": {
        "id": "zADpr0f8IcGL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Holdout and Cross Validation.**\n",
        "\n",
        "hold-out is simply when the given dataset it divided into \"train\" and \"test\" sets which are passed to the model, in this instance we are using a 70% 30% split for training and testing respectively (this approach is used in the kNN in the previous section).\n",
        "\n",
        "Sometimes knowledge from the test set can \"leak\" and lead to overfitting, to address this we can withohold a portion to the training data to use as a \"validation set\", on which the model's performance is evaluated following training and prior to final evaluation using the test set. Howevere, splitting the data into 3 sets reduces the amount of data on which we train the model.\n",
        "\n",
        "This method splits the data into \"k\" groups or \"folds\". Then the model is trained and tested k times so that each fold can be used as a validation set once. Therefore, k-fold cross validation seems to be a more robust method of training and evaluating a model as it doesnt waste as much data as the arbitrary splitting of data to make a validation set.\n",
        "\n",
        "as with the basic models int he previous section, the tree based model outperformed the KNN.\n"
      ],
      "metadata": {
        "id": "GgkTZuj97K6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "# Knn function with cross validation\n",
        "# variables k and f are the number of neighbours and number of folds to use\n",
        "\n",
        "def knn_cv(X1, y1, X2, y2, k, f):\n",
        "    knn_cv = neighbors.KNeighborsClassifier(n_neighbors = k)\n",
        "\n",
        "    # train the model with k-fold cross val\n",
        "    cv_scores = sklearn.model_selection.cross_val_score(knn_cv, X1, y1, cv = f)\n",
        "  \n",
        "    #mean and std of the cv_scores\n",
        "    return(print(\"KNN cv_scores mean:{}\".format(np.mean(cv_scores))),\n",
        "           print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cv_scores.mean(), cv_scores.std())))\n",
        "\n",
        "# decsision tree function with cross validation\n",
        "def tree_cv(X1, y1, X2, y2, f):\n",
        "    Tree = tree.DecisionTreeClassifier()\n",
        "    cv_scores = sklearn.model_selection.cross_val_score(Tree, X1, y1, cv = f)\n",
        "    return(print(\"decision tree cv_scores mean:{}\".format(np.mean(cv_scores))),\n",
        "           print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cv_scores.mean(), cv_scores.std())))\n",
        "\n",
        "knn_cv(X_train, y_train, X_test,  y_test, 5, 10)\n",
        "print(\"\\n\")\n",
        "tree_cv(X_train, y_train, X_test,  y_test, 10) \n"
      ],
      "metadata": {
        "id": "tvBZH6ilInsA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a71c4e38-b3a5-4793-d08e-fd4d8a729c76"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN cv_scores mean:0.8881481481481481\n",
            "0.89 accuracy with a standard deviation of 0.03\n",
            "\n",
            "\n",
            "decision tree cv_scores mean:0.9807407407407409\n",
            "0.98 accuracy with a standard deviation of 0.02\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Hypereparameter tuning using grid search CV.\n",
        "\n",
        "the hyperparameters of a model are the parameters that are set prior to training such as the number of the number of neighbours to choose in a Knn. the defaults set by scikit Learn are not always the optimal values and therefore it can eb beneficial to find the best hyperparamers for your data.\n",
        "\n",
        "with respect to tree-based classifiers the hyperparameters include the max depth and the max number of leaf nodes. A max depth of 11 resulted in a training accuracy of 1 and a validation accuracy of 0.98, thus we can set the model's max depth hyperparameter to 11 prior to training as it is the optimal value for this hyperparameter.\n",
        "\n",
        "in the following cells i use Grid search to identify optimal hyperparamters for my models. Grid search picks out a grid of hyperparameter values and evaluates all of them. there ar a number of different methods to tune the parameters such as random search and manually searching.\n",
        "\n",
        "using gridsearch to identify the optimal hyperparameters for each model, we found that n=1 was tthe best number of neighbours to use in the KNN. As for the decsision tree the max depth of 11 was the most optimum value."
      ],
      "metadata": {
        "id": "YWdNdZHW_XZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# knn classifir to use in \"GridSearchCV\"\n",
        "knn1 = neighbors.KNeighborsClassifier()\n",
        "\n",
        "# dictionary of all vals of K (neighbours) to test for using grid search\n",
        "param_grid = {\"n_neighbors\": np.arange(1, 25)}\n",
        "\n",
        "gs_cv = GridSearchCV(knn1, param_grid, cv = 10 )#fit model to data\n",
        "gs_cv.fit(X_train, y_train)\n",
        "\n",
        "gs_cv.best_params_, gs_cv.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLY-YROR_gXC",
        "outputId": "6f7a1a8f-66f0-46b4-d153-8791da2b1b5e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'n_neighbors': 1}, 0.9)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grid search for optimal Decision Tree hyperparams\n",
        "depth_TrainAcc = {}\n",
        "depth_ValAcc = {}\n",
        "for max_d in range(1,25):\n",
        "    model = sklearn.tree.DecisionTreeClassifier(max_depth=max_d, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    depth_TrainAcc[max_d] = (model.score(X_train, y_train))\n",
        "    depth_ValAcc[max_d] = (model.score(X_test, y_test))\n",
        "\n",
        "# max_T is the key (max depth) with the higest corresponding training accuracy\n",
        "# use that key to get the corresponding validation accuracy \n",
        "max_T = max(depth_TrainAcc, key = depth_TrainAcc.get)\n",
        "print(depth_TrainAcc[max_T], depth_ValAcc[max_T], max_T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukSp9BEWDESB",
        "outputId": "32681500-2456-441f-d80c-d1904c55f06c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 0.9810017271157168 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## Feature Extraction/ Reduction.\n",
        "\n",
        "from running the \"df.shape\" function on the dataframe at the begining of this document we can see that there are 328 columns. taking into account one of these is our binary tarvet variable, we have 327 different features or variables. Because of the curse of dimensionality we can expect the performance of our model to degrade when working with a large number of features and thus reducing the dimensionality or number of features could serve to improve performance.\n",
        "\n",
        "By using PCA we can transorm the features into linear or non-linear combinations, reducing the dinmensionality of the data whilst preserving the information. The overall aim of this reduction technique is to identify vectors which explain the variance and structure of the data and in doing so we filter out any noise and redundancy.\n",
        "\n",
        "in the following cells of code, PCA is used to reduce dimensionality of the data. To decide what number of principle components (PC's) to retain, we carry out PCA on all 327 features and calculate the cumulative explained variance for each. using \"np.argmax(cumsum >= 0.95) + 1\" we can find the minimum number of PC's required to preserve 95% of the data's variance.\n",
        "\n",
        "Using 22 PC's and then training and fitting the model on this now reduced data, the KNN outperformed the Decision tree by quite a bit.\n"
      ],
      "metadata": {
        "id": "M13Wj-WnIwuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lrsXrkSJzZJ",
        "outputId": "2066c7a0-68e8-433e-f882-5c0985610173"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1350, 327)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pca = PCA()\n",
        "pca.fit(X_train)\n",
        "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
        "\n",
        "\n",
        "d = np.argmax(cumsum >= 0.95) + 1\n",
        "d # this is the min number of PC's required to preserve 95% of the data's variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcDtjlctI6NI",
        "outputId": "4b80ffef-4712-4b35-8778-7fb5e83aaa1b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components = 22)\n",
        "train_features = pca.fit_transform(X_train)\n",
        "test_features = pca.fit_transform(X_test)\n",
        "print(\"Training set size \", train_features.shape)\n",
        "\n",
        "knn1 = neighbors.KNeighborsClassifier()\n",
        "\n",
        "parameters = {'n_neighbors': [1, 3, 5, 7, 11]}\n",
        "clf = sklearn.model_selection.GridSearchCV(knn1, parameters)\n",
        "clf.fit(train_features, y_train)\n",
        "print(\"The best classifier is:\", clf.best_estimator_)\n",
        "print(\"Its accuracy is:\",clf.best_score_)\n",
        "print(\"Its parameters are:\",clf.best_params_)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "decision_tree(train_features, y_train, test_features, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg-CJtAYKTYE",
        "outputId": "f55838f0-b054-4d5d-8efd-4aed70f58827"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size  (1350, 22)\n",
            "The best classifier is: KNeighborsClassifier(n_neighbors=1)\n",
            "Its accuracy is: 0.8977777777777778\n",
            "Its parameters are: {'n_neighbors': 1}\n",
            "\n",
            "\n",
            "Accuracy of Decision Tree: 0.5785837651122625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## Feature Normalisation.\n",
        "\n",
        "distamce based classifiers such as KNN's are typically more sensitive to a feature's range as they are using the distances between data points to assess similarity. if two features in the data are on vastly different scales the features with a higher magnitude can be assigned more importance so to speak and therefore methods such as min-Max scaling, which rescales all the features to a range between 0 and 1 can be used to address this challenge. \n",
        "\n",
        "in the following cells we will compare the models trained on the normalised datasets which we used in part one and models trained on non-normalised data.\n",
        "\n",
        "the using the normalised datasets we see that the Knn performs better than when using the un-scaled data, this is to be expected. Tree based algorithms are known to be rather insensitive to the scales of the features in the data. this fact is evident from the accuracies of the following cell of code which outputs the accuracies of a KNN and decison tree models which have both been passed first the normalised data and then the non-normalised data.\n"
      ],
      "metadata": {
        "id": "Ke3Em0I9Qyyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X1_train, X1_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
        "\n",
        "knn(X_train, y_train, X_test,  y_test, 5) # normalised datasets\n",
        "knn(X1_train, y_train, X1_test,  y_test, 5)\n",
        "\n",
        "decision_tree(X_train, y_train, X_test,  y_test) #non-normal data\n",
        "decision_tree(X1_train, y_train, X1_test,  y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4ghUnplSXoY",
        "outputId": "ae626f97-7f31-4565-fae6-fbdad5776716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of knn: 0.8911917098445595\n",
            "Accuracy of knn: 0.8013816925734024\n",
            "Accuracy of basic Decision Tree: 0.9706390328151986\n",
            "Accuracy of basic Decision Tree: 0.9671848013816926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New classifier (10 Marks)\n",
        "\n",
        "Replicate the previous task for a classifier that we did not cover in class. So different than K-NN and decision trees. Briefly describe your choice.\n",
        "Try to create the best model for the given dataset.\n",
        "Save your best model into your github. And create a single code cell that loads it and evaluate it on the following test dataset:\n",
        "https://github.com/andvise/DataAnalyticsDatasets/blob/main/dm_assignment2/sat_dataset_test.csv\n",
        "\n",
        "This link currently contains a sample of the training set. The real test set will be released after the submission. I should be able to run the code cell independently, load all the libraries you need as well."
      ],
      "metadata": {
        "id": "FYoMg0EZIrNd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "A support vector machine was chosen as the new classifier. this was chosen seeing as SVMs are good at handling data with high dimensionality. the methods from the previous section were applied but as their background has been briefly discussed above i will only briefly metion them here with regards to the following SVM.\n",
        "\n",
        "## Holdout and Cross Validation.\n",
        "the final cell of code in this section contains the best performing model i have made thus far. 10-fold cross validation is carried out and the accuracy, precision and recall are all approximately 90%. from the confusion matrix contained in the output we can see 267 true negative and 287 true positive cases identified, whilst there were only 6 and 19 false negatives and false positives respectively. \n",
        "\n",
        "## Hyperparameter Tuning.\n",
        "The hyperparameter grid was made to include regualrisation parameters (C), the kernel coefficient (gamma) and the \"rbf\" (default), and \"linear\" kernel types. of which the following configuration appeard to be the most efficient; \n",
        "(C=10, gamma=1, kernel='linear').\n",
        "\n",
        "## Feature Reduction.\n",
        "using the \"train_features\" and \"test_features\" created in the cells in the previous section as part of the PCA for data reduction, the SVM was trained and tested. However, using these sets drastically reduced the accuracy (by roughly 30%) and thus following this the normalised X_train and X_test sets were used in following models.\n",
        "\n",
        "## Data Normalisation.\n",
        "It is usually a good idea to normalise the data befor passing them to any model, but just for comparison I tried fitting the SVM using the non-normal data as was done in the above sections for the KNN and decision tree. when executing the cell of code the runtime was extremely long and i have no worthwhile comparison other than the normalising the data is best as it shortens runtime compared to using non-normal data.   \n"
      ],
      "metadata": {
        "id": "rzHXDa6A6Qz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# function to make linear SVM, fit data and evaluate performance \n",
        "# by returning confusion matrix and a classification report\n",
        "def linear_SVM(X1, y1, X2, y2):\n",
        "  svclassifier = SVC()\n",
        "  svclassifier.fit(X1, y1)\n",
        "  y_pred = svclassifier.predict(X2)\n",
        "\n",
        "  conf_mat = confusion_matrix(y2,y_pred)\n",
        "  classif_rep = classification_report(y2,y_pred)\n",
        "  return(print(\"Accuracy of SVM:\", sklearn.metrics.accuracy_score(y2, y_pred)), \n",
        "         print(\"\\n\"),\n",
        "         print(conf_mat),\n",
        "         print(\"\\n\"),\n",
        "         print(classif_rep))\n",
        "\n",
        "\n",
        "def linear_SVM_cv(X1, y1, X2, y2, f):\n",
        "    svclassifier = SVC()\n",
        "\n",
        "    # train the model with k-fold cross val\n",
        "    cv_scores = sklearn.model_selection.cross_val_score(svclassifier, X1, y1, cv = f)\n",
        "  \n",
        "    #mean and std of the cv_scores\n",
        "    return(print(\"SVM cv_scores mean:{}\".format(np.mean(cv_scores))),\n",
        "           print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cv_scores.mean(), cv_scores.std())))\n",
        "\n",
        "\n",
        "linear_SVM(X_train, y_train, X_test,  y_test)\n",
        "\n",
        "# calling the function using \"train_features\" and \"test_features\" defined in the PCA portion above\n",
        "# linear_SVM(train_features, y_train, test_features, y_test)\n",
        "\n",
        "# calling the function using non-normalised data\n",
        "#linear_SVM(X1_train, y_train, X1_test,  y_test)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVEJj0JXa7si",
        "outputId": "e47f6857-1150-4bd8-b97f-81f771a0fbf8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of SVM: 0.8963730569948186\n",
            "\n",
            "\n",
            "[[258  28]\n",
            " [ 32 261]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.90      0.90       286\n",
            "           1       0.90      0.89      0.90       293\n",
            "\n",
            "    accuracy                           0.90       579\n",
            "   macro avg       0.90      0.90      0.90       579\n",
            "weighted avg       0.90      0.90      0.90       579\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_SVM_cv(X_train, y_train, X_test,  y_test, 12) # 10-fold CV in a linear SVM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVEa-XUKyg_j",
        "outputId": "6d76af67-24bc-41a9-bce3-6f8c5dfc6572"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM cv_scores mean:0.891118836915297\n",
            "0.89 accuracy with a standard deviation of 0.03\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf', 'linear', 'sigmoid']}\n",
        "\n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "\n",
        "# fitting the model for grid search\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        " \n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDVKb9lg2JDp",
        "outputId": "b68d1ceb-2d91-48b9-f741-a31880d3032e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 75 candidates, totalling 375 fits\n",
            "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.848 total time=   0.3s\n",
            "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.822 total time=   0.3s\n",
            "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.904 total time=   0.3s\n",
            "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.874 total time=   0.3s\n",
            "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.841 total time=   0.3s\n",
            "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.911 total time=   0.1s\n",
            "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.885 total time=   0.1s\n",
            "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.930 total time=   0.1s\n",
            "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.904 total time=   0.1s\n",
            "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.889 total time=   0.1s\n",
            "[CV 1/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.507 total time=   0.2s\n",
            "[CV 2/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.507 total time=   0.2s\n",
            "[CV 3/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.507 total time=   0.2s\n",
            "[CV 4/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.504 total time=   0.2s\n",
            "[CV 5/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.504 total time=   0.2s\n",
            "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.859 total time=   0.2s\n",
            "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.856 total time=   0.2s\n",
            "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.889 total time=   0.2s\n",
            "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.889 total time=   0.2s\n",
            "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.830 total time=   0.2s\n",
            "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.911 total time=   0.1s\n",
            "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.885 total time=   0.1s\n",
            "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.930 total time=   0.1s\n",
            "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.904 total time=   0.1s\n",
            "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.889 total time=   0.1s\n",
            "[CV 1/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.507 total time=   0.3s\n",
            "[CV 2/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.507 total time=   0.3s\n",
            "[CV 3/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.507 total time=   0.3s\n",
            "[CV 4/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.504 total time=   0.3s\n",
            "[CV 5/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.504 total time=   0.3s\n",
            "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.800 total time=   0.3s\n",
            "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.778 total time=   0.3s\n",
            "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.811 total time=   0.3s\n",
            "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.778 total time=   0.3s\n",
            "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.741 total time=   0.3s\n",
            "[CV 1/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.911 total time=   0.1s\n",
            "[CV 2/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.885 total time=   0.1s\n",
            "[CV 3/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.930 total time=   0.1s\n",
            "[CV 4/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.904 total time=   0.1s\n",
            "[CV 5/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.889 total time=   0.1s\n",
            "[CV 1/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.744 total time=   0.3s\n",
            "[CV 2/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.719 total time=   0.2s\n",
            "[CV 3/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.767 total time=   0.2s\n",
            "[CV 4/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.756 total time=   0.2s\n",
            "[CV 5/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.704 total time=   0.3s\n",
            "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.507 total time=   0.3s\n",
            "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.507 total time=   0.3s\n",
            "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.507 total time=   0.3s\n",
            "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.504 total time=   0.3s\n",
            "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.504 total time=   0.3s\n",
            "[CV 1/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.911 total time=   0.1s\n",
            "[CV 2/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.885 total time=   0.1s\n",
            "[CV 3/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.930 total time=   0.1s\n",
            "[CV 4/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.904 total time=   0.1s\n",
            "[CV 5/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.889 total time=   0.1s\n",
            "[CV 1/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.507 total time=   0.2s\n",
            "[CV 2/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.507 total time=   0.2s\n",
            "[CV 3/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.507 total time=   0.2s\n",
            "[CV 4/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.504 total time=   0.2s\n",
            "[CV 5/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.504 total time=   0.2s\n",
            "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.507 total time=   0.3s\n",
            "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.507 total time=   0.3s\n",
            "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.507 total time=   0.4s\n",
            "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.504 total time=   0.4s\n",
            "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.504 total time=   0.4s\n",
            "[CV 1/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.911 total time=   0.1s\n",
            "[CV 2/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.885 total time=   0.1s\n",
            "[CV 3/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.930 total time=   0.1s\n",
            "[CV 4/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.904 total time=   0.1s\n",
            "[CV 5/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.889 total time=   0.1s\n",
            "[CV 1/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.507 total time=   0.4s\n",
            "[CV 2/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.507 total time=   0.4s\n",
            "[CV 3/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.507 total time=   0.3s\n",
            "[CV 4/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.504 total time=   0.3s\n",
            "[CV 5/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.504 total time=   0.4s\n",
            "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.911 total time=   0.3s\n",
            "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.885 total time=   0.4s\n",
            "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.900 total time=   0.3s\n",
            "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.922 total time=   0.3s\n",
            "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.881 total time=   0.3s\n",
            "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=0.930 total time=   0.1s\n",
            "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.952 total time=   0.1s\n",
            "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=0.944 total time=   0.1s\n",
            "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.941 total time=   0.1s\n",
            "[CV 1/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.507 total time=   0.3s\n",
            "[CV 2/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.507 total time=   0.3s\n",
            "[CV 3/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.507 total time=   0.3s\n",
            "[CV 4/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.504 total time=   0.3s\n",
            "[CV 5/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.504 total time=   0.2s\n",
            "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.889 total time=   0.1s\n",
            "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.900 total time=   0.1s\n",
            "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.919 total time=   0.1s\n",
            "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.915 total time=   0.1s\n",
            "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.889 total time=   0.1s\n",
            "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.930 total time=   0.1s\n",
            "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.952 total time=   0.1s\n",
            "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.944 total time=   0.1s\n",
            "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.941 total time=   0.1s\n",
            "[CV 1/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.481 total time=   0.3s\n",
            "[CV 2/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.493 total time=   0.3s\n",
            "[CV 3/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.511 total time=   0.3s\n",
            "[CV 4/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.489 total time=   0.3s\n",
            "[CV 5/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.500 total time=   0.3s\n",
            "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.893 total time=   0.2s\n",
            "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.870 total time=   0.2s\n",
            "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.911 total time=   0.2s\n",
            "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.889 total time=   0.2s\n",
            "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.867 total time=   0.2s\n",
            "[CV 1/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 2/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.930 total time=   0.1s\n",
            "[CV 3/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.952 total time=   0.1s\n",
            "[CV 4/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.944 total time=   0.1s\n",
            "[CV 5/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.941 total time=   0.1s\n",
            "[CV 1/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.833 total time=   0.2s\n",
            "[CV 2/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.841 total time=   0.2s\n",
            "[CV 3/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.867 total time=   0.2s\n",
            "[CV 4/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.830 total time=   0.2s\n",
            "[CV 5/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.822 total time=   0.2s\n",
            "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.804 total time=   0.3s\n",
            "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.785 total time=   0.3s\n",
            "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.819 total time=   0.3s\n",
            "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.796 total time=   0.3s\n",
            "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.767 total time=   0.3s\n",
            "[CV 1/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 2/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.930 total time=   0.1s\n",
            "[CV 3/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.952 total time=   0.1s\n",
            "[CV 4/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.944 total time=   0.1s\n",
            "[CV 5/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.941 total time=   0.1s\n",
            "[CV 1/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.744 total time=   0.2s\n",
            "[CV 2/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.733 total time=   0.2s\n",
            "[CV 3/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.781 total time=   0.2s\n",
            "[CV 4/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.711 total time=   0.2s\n",
            "[CV 5/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.730 total time=   0.2s\n",
            "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.507 total time=   0.3s\n",
            "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.507 total time=   0.3s\n",
            "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.507 total time=   0.3s\n",
            "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.504 total time=   0.3s\n",
            "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.504 total time=   0.3s\n",
            "[CV 1/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 2/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.930 total time=   0.1s\n",
            "[CV 3/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.952 total time=   0.1s\n",
            "[CV 4/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.944 total time=   0.1s\n",
            "[CV 5/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.941 total time=   0.1s\n",
            "[CV 1/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.507 total time=   0.2s\n",
            "[CV 2/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.507 total time=   0.2s\n",
            "[CV 3/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.507 total time=   0.2s\n",
            "[CV 4/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.504 total time=   0.2s\n",
            "[CV 5/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.504 total time=   0.2s\n",
            "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.941 total time=   0.2s\n",
            "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.900 total time=   0.2s\n",
            "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.933 total time=   0.2s\n",
            "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.941 total time=   0.2s\n",
            "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.885 total time=   0.2s\n",
            "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.970 total time=   0.1s\n",
            "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=0.959 total time=   0.1s\n",
            "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=0.970 total time=   0.1s\n",
            "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=0.959 total time=   0.1s\n",
            "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=0.963 total time=   0.1s\n",
            "[CV 1/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.507 total time=   0.2s\n",
            "[CV 2/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.507 total time=   0.2s\n",
            "[CV 3/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.507 total time=   0.2s\n",
            "[CV 4/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.504 total time=   0.2s\n",
            "[CV 5/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.504 total time=   0.2s\n",
            "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.930 total time=   0.1s\n",
            "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.922 total time=   0.1s\n",
            "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.1s\n",
            "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.948 total time=   0.1s\n",
            "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.915 total time=   0.1s\n",
            "[CV 1/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.970 total time=   0.1s\n",
            "[CV 2/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.959 total time=   0.1s\n",
            "[CV 3/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.970 total time=   0.1s\n",
            "[CV 4/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.959 total time=   0.1s\n",
            "[CV 5/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.963 total time=   0.1s\n",
            "[CV 1/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.459 total time=   0.2s\n",
            "[CV 2/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.504 total time=   0.2s\n",
            "[CV 3/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.433 total time=   0.2s\n",
            "[CV 4/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.422 total time=   0.2s\n",
            "[CV 5/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.507 total time=   0.2s\n",
            "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.904 total time=   0.1s\n",
            "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.904 total time=   0.1s\n",
            "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.922 total time=   0.1s\n",
            "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.933 total time=   0.1s\n",
            "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.893 total time=   0.1s\n",
            "[CV 1/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.970 total time=   0.1s\n",
            "[CV 2/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.959 total time=   0.1s\n",
            "[CV 3/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.970 total time=   0.1s\n",
            "[CV 4/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.959 total time=   0.1s\n",
            "[CV 5/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.963 total time=   0.1s\n",
            "[CV 1/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.885 total time=   0.1s\n",
            "[CV 2/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.863 total time=   0.1s\n",
            "[CV 3/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.915 total time=   0.1s\n",
            "[CV 4/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.889 total time=   0.1s\n",
            "[CV 5/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.878 total time=   0.1s\n",
            "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.878 total time=   0.2s\n",
            "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.867 total time=   0.2s\n",
            "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.911 total time=   0.2s\n",
            "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.881 total time=   0.2s\n",
            "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.848 total time=   0.2s\n",
            "[CV 1/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.970 total time=   0.1s\n",
            "[CV 2/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.959 total time=   0.1s\n",
            "[CV 3/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.970 total time=   0.1s\n",
            "[CV 4/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.959 total time=   0.1s\n",
            "[CV 5/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.963 total time=   0.1s\n",
            "[CV 1/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.874 total time=   0.2s\n",
            "[CV 2/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.859 total time=   0.2s\n",
            "[CV 3/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.885 total time=   0.2s\n",
            "[CV 4/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.856 total time=   0.2s\n",
            "[CV 5/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.841 total time=   0.2s\n",
            "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.811 total time=   0.3s\n",
            "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.767 total time=   0.3s\n",
            "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.819 total time=   0.3s\n",
            "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.793 total time=   0.3s\n",
            "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.767 total time=   0.3s\n",
            "[CV 1/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.970 total time=   0.1s\n",
            "[CV 2/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.959 total time=   0.1s\n",
            "[CV 3/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.970 total time=   0.1s\n",
            "[CV 4/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.959 total time=   0.1s\n",
            "[CV 5/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.963 total time=   0.1s\n",
            "[CV 1/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.744 total time=   0.2s\n",
            "[CV 2/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.733 total time=   0.2s\n",
            "[CV 3/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.781 total time=   0.2s\n",
            "[CV 4/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.711 total time=   0.2s\n",
            "[CV 5/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.730 total time=   0.2s\n",
            "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.941 total time=   0.2s\n",
            "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.896 total time=   0.2s\n",
            "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.933 total time=   0.2s\n",
            "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.941 total time=   0.2s\n",
            "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.885 total time=   0.2s\n",
            "[CV 1/5] END .....C=100, gamma=1, kernel=linear;, score=0.963 total time=   0.1s\n",
            "[CV 2/5] END .....C=100, gamma=1, kernel=linear;, score=0.952 total time=   0.1s\n",
            "[CV 3/5] END .....C=100, gamma=1, kernel=linear;, score=0.959 total time=   0.1s\n",
            "[CV 4/5] END .....C=100, gamma=1, kernel=linear;, score=0.967 total time=   0.1s\n",
            "[CV 5/5] END .....C=100, gamma=1, kernel=linear;, score=0.967 total time=   0.1s\n",
            "[CV 1/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.507 total time=   0.2s\n",
            "[CV 2/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.507 total time=   0.2s\n",
            "[CV 3/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.507 total time=   0.2s\n",
            "[CV 4/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.504 total time=   0.2s\n",
            "[CV 5/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.504 total time=   0.2s\n",
            "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.956 total time=   0.1s\n",
            "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.922 total time=   0.1s\n",
            "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.963 total time=   0.1s\n",
            "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.941 total time=   0.1s\n",
            "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.937 total time=   0.1s\n",
            "[CV 1/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.963 total time=   0.1s\n",
            "[CV 2/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.952 total time=   0.1s\n",
            "[CV 3/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.959 total time=   0.1s\n",
            "[CV 4/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.967 total time=   0.1s\n",
            "[CV 5/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.967 total time=   0.1s\n",
            "[CV 1/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.459 total time=   0.2s\n",
            "[CV 2/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.496 total time=   0.2s\n",
            "[CV 3/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.433 total time=   0.2s\n",
            "[CV 4/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.437 total time=   0.2s\n",
            "[CV 5/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.496 total time=   0.2s\n",
            "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.959 total time=   0.1s\n",
            "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.1s\n",
            "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.963 total time=   0.1s\n",
            "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.963 total time=   0.1s\n",
            "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.1s\n",
            "[CV 1/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.963 total time=   0.1s\n",
            "[CV 2/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.952 total time=   0.1s\n",
            "[CV 3/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.959 total time=   0.1s\n",
            "[CV 4/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.967 total time=   0.1s\n",
            "[CV 5/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.967 total time=   0.1s\n",
            "[CV 1/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.859 total time=   0.1s\n",
            "[CV 2/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.826 total time=   0.1s\n",
            "[CV 3/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.863 total time=   0.1s\n",
            "[CV 4/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.881 total time=   0.1s\n",
            "[CV 5/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.837 total time=   0.1s\n",
            "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.900 total time=   0.1s\n",
            "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.911 total time=   0.1s\n",
            "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.930 total time=   0.1s\n",
            "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.933 total time=   0.1s\n",
            "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.896 total time=   0.1s\n",
            "[CV 1/5] END .C=100, gamma=0.001, kernel=linear;, score=0.963 total time=   0.1s\n",
            "[CV 2/5] END .C=100, gamma=0.001, kernel=linear;, score=0.952 total time=   0.1s\n",
            "[CV 3/5] END .C=100, gamma=0.001, kernel=linear;, score=0.959 total time=   0.1s\n",
            "[CV 4/5] END .C=100, gamma=0.001, kernel=linear;, score=0.967 total time=   0.1s\n",
            "[CV 5/5] END .C=100, gamma=0.001, kernel=linear;, score=0.967 total time=   0.1s\n",
            "[CV 1/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.911 total time=   0.1s\n",
            "[CV 2/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.889 total time=   0.1s\n",
            "[CV 3/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.930 total time=   0.1s\n",
            "[CV 4/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.904 total time=   0.1s\n",
            "[CV 5/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.889 total time=   0.1s\n",
            "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.874 total time=   0.2s\n",
            "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.867 total time=   0.2s\n",
            "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.911 total time=   0.2s\n",
            "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.878 total time=   0.2s\n",
            "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.848 total time=   0.2s\n",
            "[CV 1/5] END C=100, gamma=0.0001, kernel=linear;, score=0.963 total time=   0.1s\n",
            "[CV 2/5] END C=100, gamma=0.0001, kernel=linear;, score=0.952 total time=   0.1s\n",
            "[CV 3/5] END C=100, gamma=0.0001, kernel=linear;, score=0.959 total time=   0.1s\n",
            "[CV 4/5] END C=100, gamma=0.0001, kernel=linear;, score=0.967 total time=   0.1s\n",
            "[CV 5/5] END C=100, gamma=0.0001, kernel=linear;, score=0.967 total time=   0.1s\n",
            "[CV 1/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.874 total time=   0.2s\n",
            "[CV 2/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.859 total time=   0.2s\n",
            "[CV 3/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.885 total time=   0.2s\n",
            "[CV 4/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.856 total time=   0.2s\n",
            "[CV 5/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.841 total time=   0.2s\n",
            "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.941 total time=   0.2s\n",
            "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.896 total time=   0.2s\n",
            "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.933 total time=   0.2s\n",
            "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.941 total time=   0.2s\n",
            "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.885 total time=   0.2s\n",
            "[CV 1/5] END ....C=1000, gamma=1, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 2/5] END ....C=1000, gamma=1, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 3/5] END ....C=1000, gamma=1, kernel=linear;, score=0.967 total time=   0.1s\n",
            "[CV 4/5] END ....C=1000, gamma=1, kernel=linear;, score=0.956 total time=   0.1s\n",
            "[CV 5/5] END ....C=1000, gamma=1, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 1/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.507 total time=   0.2s\n",
            "[CV 2/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.507 total time=   0.2s\n",
            "[CV 3/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.507 total time=   0.2s\n",
            "[CV 4/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.504 total time=   0.2s\n",
            "[CV 5/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.504 total time=   0.2s\n",
            "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.959 total time=   0.1s\n",
            "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.930 total time=   0.1s\n",
            "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.963 total time=   0.1s\n",
            "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.941 total time=   0.1s\n",
            "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.937 total time=   0.1s\n",
            "[CV 1/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 2/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 3/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.967 total time=   0.1s\n",
            "[CV 4/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.956 total time=   0.1s\n",
            "[CV 5/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 1/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.463 total time=   0.2s\n",
            "[CV 2/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.489 total time=   0.2s\n",
            "[CV 3/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.426 total time=   0.2s\n",
            "[CV 4/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.563 total time=   0.1s\n",
            "[CV 5/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.496 total time=   0.2s\n",
            "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.959 total time=   0.1s\n",
            "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.930 total time=   0.1s\n",
            "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.974 total time=   0.1s\n",
            "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.956 total time=   0.1s\n",
            "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.956 total time=   0.1s\n",
            "[CV 1/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 2/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 3/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.967 total time=   0.1s\n",
            "[CV 4/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.956 total time=   0.1s\n",
            "[CV 5/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 1/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.815 total time=   0.1s\n",
            "[CV 2/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.841 total time=   0.1s\n",
            "[CV 3/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.833 total time=   0.1s\n",
            "[CV 4/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.874 total time=   0.1s\n",
            "[CV 5/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.819 total time=   0.1s\n",
            "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.963 total time=   0.1s\n",
            "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.933 total time=   0.1s\n",
            "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.959 total time=   0.1s\n",
            "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.948 total time=   0.1s\n",
            "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.941 total time=   0.1s\n",
            "[CV 1/5] END C=1000, gamma=0.001, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 2/5] END C=1000, gamma=0.001, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 3/5] END C=1000, gamma=0.001, kernel=linear;, score=0.967 total time=   0.1s\n",
            "[CV 4/5] END C=1000, gamma=0.001, kernel=linear;, score=0.956 total time=   0.1s\n",
            "[CV 5/5] END C=1000, gamma=0.001, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 1/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.948 total time=   0.1s\n",
            "[CV 2/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.930 total time=   0.1s\n",
            "[CV 3/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.952 total time=   0.1s\n",
            "[CV 4/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.944 total time=   0.1s\n",
            "[CV 5/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.941 total time=   0.1s\n",
            "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.904 total time=   0.1s\n",
            "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.911 total time=   0.1s\n",
            "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.930 total time=   0.1s\n",
            "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.930 total time=   0.1s\n",
            "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.900 total time=   0.1s\n",
            "[CV 1/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 2/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 3/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.967 total time=   0.1s\n",
            "[CV 4/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.956 total time=   0.1s\n",
            "[CV 5/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.948 total time=   0.1s\n",
            "[CV 1/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.911 total time=   0.1s\n",
            "[CV 2/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.885 total time=   0.1s\n",
            "[CV 3/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.930 total time=   0.1s\n",
            "[CV 4/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.904 total time=   0.1s\n",
            "[CV 5/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.889 total time=   0.1s\n",
            "{'C': 10, 'gamma': 1, 'kernel': 'linear'}\n",
            "SVC(C=10, gamma=1, kernel='linear')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_predictions = grid.predict(X_test)\n",
        " \n",
        "# print classification report\n",
        "print(sklearn.metrics.accuracy_score(y_test, grid_predictions),\n",
        "      (\"\\n\"),\n",
        "      confusion_matrix(y_test, grid_predictions), \n",
        "      classification_report(y_test, grid_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sPLAZLX3N9b",
        "outputId": "2802de0e-ebcd-4533-f792-ecae11238b12"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9568221070811744 \n",
            " [[267  19]\n",
            " [  6 287]]               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.93      0.96       286\n",
            "           1       0.94      0.98      0.96       293\n",
            "\n",
            "    accuracy                           0.96       579\n",
            "   macro avg       0.96      0.96      0.96       579\n",
            "weighted avg       0.96      0.96      0.96       579\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the best model i ahve thus far\n",
        "\n",
        "def best_svm(X1, y1, X2, y2, f):\n",
        "  svclassifier = SVC(C=10, gamma=1, kernel='linear')\n",
        "  cv_scores = sklearn.model_selection.cross_val_score(svclassifier, X1, y1, cv = f)\n",
        "\n",
        "  mean_score = np.mean(cv_scores)\n",
        "\n",
        "  svclassifier.fit(X1, y1)\n",
        "  y_pred = svclassifier.predict(X2)\n",
        "\n",
        "  conf_mat = confusion_matrix(y2,y_pred)\n",
        "  classif_rep = classification_report(y2,y_pred)\n",
        "  return(#print(\"Accuracy of SVM:\", sklearn.metrics.accuracy_score(y2, y_pred)), \"mean = \", mean_score, \n",
        "         print(\"\\n\"),\n",
        "         print(conf_mat),\n",
        "         print(\"\\n\"),\n",
        "         print(classif_rep))\n",
        "  \n",
        "\n",
        "best_svm(X_train, y_train, X_test,  y_test, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39qnCMyb4qyy",
        "outputId": "7ab5d32f-cfc9-4923-c11c-a0c54fe96e78"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[[267  19]\n",
            " [  6 287]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.93      0.96       286\n",
            "           1       0.94      0.98      0.96       293\n",
            "\n",
            "    accuracy                           0.96       579\n",
            "   macro avg       0.96      0.96      0.96       579\n",
            "weighted avg       0.96      0.96      0.96       579\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"blue\">FOR GRADING ONLY</font>\n",
        "\n",
        "Save your best model into your github. And create a single code cell that loads it and evaluate it on the following test dataset: \n",
        "https://github.com/andvise/DataAnalyticsDatasets/blob/main/dm_assignment2/sat_dataset_test.csv"
      ],
      "metadata": {
        "id": "Q01BjiiCJTR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump, load\n",
        "from io import BytesIO\n",
        "import requests\n",
        "\n",
        "# INSERT YOUR MODEL'S URL\n",
        "mLink = 'URL_OF_YOUR_MODEL_SAVED_IN_YOUR_GITHUB_REPOSITORY?raw=true'\n",
        "mfile = BytesIO(requests.get(mLink).content)\n",
        "model = load(mfile)\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "IWx4lyuQI929"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w-k6H-1ZKTYo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}